上一篇文章使用了rvest包对NCBI网页进行爬虫，但是爬虫内容仅限于单一网页的可见部分。如果网页内容过多，必须进行分页，则需要使用循环对网页进行爬虫。
本文也有局限性。在写本文期间对NCBI的pubmed数据库进行流感病毒文献爬虫。https://www.ncbi.nlm.nih.gov/pubmed/?term=influenza+A+virus这是第一页，
当点到第二页时发现网页变成https://www.ncbi.nlm.nih.gov/pubmed。暂时没有想到较好办法，只能网页内设置单页出现items为200.减少爬虫次数。
对于电影网页，如俄罗斯电影网站http://vexmovies.org/free-movies则可以使用/page/1~n进行循环爬虫。

![image](https://github.com/MisgaXiong/Web-Spider/blob/master/%E4%BF%84%E7%BD%97%E6%96%AF%E7%94%B5%E5%BD%B1%E7%BD%91.png)


`library(rvest)
library(ggplot2)
b<-NULL
for(i in 1:3){
  url<-paste("http://vexmovies.org/free-movies/page/",i,sep = "")
  dy<-read_html(url)
  dyxx<-dy%>%
    html_nodes(css = ".fixyear")%>%
    html_text()
  b<-c(b,dyxx)
}
b<-gsub(pattern = "\n",replacement = "",b)
year<-gsub(pattern = "[A-Za-z]+|[!:-]|",replacement = "",b)
dy18<-length(year[grepl(pattern = "2018",year)])
dy17<-length(year[grepl(pattern = "2017",year)])
dy16<-length(year[grepl(pattern = "2016",year)])
dy15<-length(year[grepl(pattern = "2015",year)])
d<-c("2018年电影量","2017年电影量","2016年电影量","2015年电影量")
a<-c(dy18,dy17,dy16,dy15)
DY<-data.frame(d,a)
ggplot(DY,mapping=aes(x=d,y=a,fill=a))+geom_bar(stat = "identity")`


![image](https://github.com/MisgaXiong/Web-Spider/blob/master/Rplot02.png)
